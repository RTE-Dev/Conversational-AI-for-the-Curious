## 2.2 两种常见的架构：级联与端到端 {#2-2-common-architectures}
当前业界的语音代理实现方式主要分为两类： 
**级联架构（****Cascaded Mode****）** 和 **端到端架构（****End-to-End Mode****）**。

### 2.2.1 级联架构（Cascaded Mode） {#2-2-1-cascaded-mode}

在级联架构中，语音信号按顺序流经多个模块，每个模块负责独立的子任务：

`STT（Speech to Text） → LLM（Language Model） → TTS（Text to Speech）`

STT 模块将声音转录为文字，LLM 负责生成语义响应，TTS 再将文本转回音频播放。

<img width="790" height="414" alt="image" src="https://github.com/user-attachments/assets/72b96600-3107-4287-bd45-5bed12284d96" />


由于每个部分相互独立，开发者可以针对不同需求替换组件。例如，可以选择擅长识别口音的 STT 引擎，或切换到音色更自然的 TTS 服务。这种模块化设计让系统具有良好的可扩展性和调试性。如果其中一个组件出现问题，只需单独替换，而无需重构整个系统。

缺点也显而易见：多个环节串行传递会增加延迟；各模块需要单独部署与调试；在流式交互场景中，协调与中断逻辑会变得复杂。

尽管如此，在目前的技术阶段，级联仍然是大多数开发者和企业采用的首选方案——稳定、灵活、成本可控。

### 2.2.2 端到端架构（End-to-End Mode） {#2-2-2-end-to-end-mode}

端到端架构用单一多模态模型处理整个语音输入到语音输出的过程。

![alt text](/image/221-2.png)

用户说出一句话，系统在内部直接生成语音回应，不再显式分出“识别—生成—合成”的步骤。以 OpenAI 的 Realtime API 为例，它通过一个流式通道，实现“语音进—语音出”的连续对话。这种模式的优势非常突出：延迟极低，响应自然流畅；部署简单，不需要手动维护多个模型。

但与此同时，开发者也失去了控制权。你无法调整识别逻辑、插入工具调用，也无法查看中间文本结果。要适配新的场景，必须重新微调整个模型。此外，端到端模型的输出往往更短、更口语化，缺乏复杂推理链条。

如吴恩达在一次演讲中指出，端到端语音模型仍缺乏文本层面的验证机制，这限制了它在逻辑严谨任务中的表现。

可以说，**端到端代表了未来，但级联仍然是现在最现实的选择**。 未来几年，我们更可能看到的是二者的混合形式：在关键路径使用级联以保持可控性，辅以端到端模块提升自然度。
