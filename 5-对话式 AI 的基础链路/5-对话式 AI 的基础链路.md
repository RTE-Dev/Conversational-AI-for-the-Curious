# 5. 对话式 AI 的基础链路
> **开发者导读**
> 
> 在前面的章节中，我们已经让 AI 了解了最基础的“听见”：通过 3A 算法获得干净语音、通过 VAD 判断语音起止、通过 Turn Detection 理解对话轮次。
> 
> 但在听见之后，对话式 AI 还需要做到三件事：
> 
> 1. **听懂**用户想要表达的内容（ASR）
> 2. **理解**用户想表达的含义（ASR ）
> 3. **表达**出自然流畅的回应（TTS）
> 
> 这些模块构成了语音智能体的“思考循环”（Thinking Loop），后续也会涉及到一部分的动作执行（Function Call）。从输入音频到生成语音响应，每一个环节都直接决定用户体验的自然度与实时性。

> **本章目标：**
> 
> 本章将聚焦于 对话式 AI 的核心路径：
> 
> **ASR（语音识别）→ LLM（语义理解与决策）→ TTS（语音合成）→ Function Call（动作触发）。** 并探讨它们之间的延迟平衡、模型选择策略，以及如何为后续的 Memory 与 RAG 模块打下基础。