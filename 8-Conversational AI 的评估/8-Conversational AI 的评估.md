> # 8. Conversational AI 的评估
> **开发者导读**
> 
> 当一个 对话式 AI 能“说得对、听得懂、接得快”，它才算真正具备对话的灵魂。
> 
> 然而，衡量“对话体验”远比测一组模型指标要复杂得多——你要面对的不只是延迟、识别率或合成速度，还有**人类的感受**：自然、节奏、信任、连贯。
> 
> 这一章，我们会尝试回答一个看似简单的问题：你的 对话式 AI，到底是不是“好用”的？

> **本章目标**
> 
> 通过本章，你将了解一个兼顾性能与体验的“三维两轨”评估框架

当我们谈论“语音交互体验”的评估时，往往容易陷入一个误区——只看某一项指标（例如 ASR 的识别率、TTS 的音质评分），而忽略了整个对话体验的系统性。

对于用户来说，一次好的语音交互，既要能高效获取信息（Informational Goal），也要让他们感受到自然、被理解与愉悦（Emotional Goal）。要做到这点，AI 不仅要能“听懂”，还要能“表达”，更要能“互动”。

不同类型的 对话式 AI 在体验重点上也会有所不同：

- **服务型智能体（Service Agent）**：如语音客服、语音助理，重点在于信息获取的效率与准确性；
- **陪伴型智能体（Companion Agent）**：如 AI 伴侣、虚拟人，更强调情感连接与对话舒适度。


无论是哪一类，好的对话体验都离不开 AI 的三种核心能力：

> 理解（Understanding）、表达（Expression）与交互（Interaction）

在每一项能力的评估上，我们希望通过**基准测试**（benchmark） 和**用户导向测试 （**user test ）两条路径进行评估。

> **Benchmark** 帮你知道 AI “能做到什么”，**User Test** 则告诉你 用户“是否真的喜欢”。

而为了全面评估这些能力，我们提出一个结构化的框架：**三维两轨（Three Dimensions, Two Tracks）**。